# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-02.csv`
- Размер: 18000 строк, 39 столбцов
- Целевая переменная: `target`: 0 - 73.7%; 1 - 26.3%
- Признаки: Двух численных типов (int64, float64)

## 2. Protocol

- Разбиение: train/test: test_size=0.2, random_state=42
- Подбор: CV на train с 5 фолдами и оптимизацией по ROC_AUC
- Метрики: accuracy, F1, ROC-AUC. Accuracy важная метрика в большинстве случаев; F1 особенно важно, т.к. в target преобладает класс "0" и эта метрика помогает понять насколько модель хорошо находит "1"; ROC-AUC в моем случае можно было найти для всех моделей, являлась ключевым параметром оценки модели.

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier (baseline) - использовалась стратегия "most_frequent", параметры не подбирались
- LogisticRegression (baseline из S05) - использовалась в `Pipeline` с `StandardScaler`, подбирался параметр `C`
- DecisionTreeClassifier (контроль сложности: `max_depth` + `min_samples_leaf` )
- RandomForestClassifier - подбирали `max_depth`, `min_samples_leaf` и `max_features`. `n_samples` = 300
- HistGradientBoosting - подбирали `learning_rate`, `max_depth` и `max_leaf_nodes`

Опционально:

- StackingClassifier (с CV-логикой) - не использовался

## 4. Results

- Таблица/список финальных метрик на test по всем моделям:
    "results": [
    {
      "accuracy": 0.9052777777777777,
      "f1": 0.802547770700637,
      "roc_auc": 0.9312444324873704,
      "model": "HistGradientBoosting"
    },
    {
      "accuracy": 0.8919444444444444,
      "f1": 0.7600246761258482,
      "roc_auc": 0.9286862164828267,
      "model": "RandomForest"
    },
    {
      "accuracy": 0.8336111111111111,
      "f1": 0.6515415939499709,
      "roc_auc": 0.8373517073705398,
      "model": "DecisionTree"
    },
    {
      "accuracy": 0.8119444444444445,
      "f1": 0.5606748864373783,
      "roc_auc": 0.7976942775436185,
      "model": "LogisticRegression"
    },
    {
      "accuracy": 0.7375,
      "f1": 0.0,
      "roc_auc": 0.5,
      "model": "DummyClassifier"
    }
  ]
- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснение:
    Среди моделей победил HistGradientBoosting. Он не сильно обогнал Random Forest по `accuracy` и `ROC-AUC`, но смог заметно улучшить `f1-score`. Ансамбли хорошо видят нелинейное взаимодействие (которое присутствует в датасете), но у GradientBoosting преумещество в виде обучения на ошибках и меньшей чувствительности к шуму.

## 5. Analysis

- Устойчивость: что будет, если поменять `random_state` (хотя бы 5 прогонов для 1-2 моделей) – кратко   

|**42** | Tree | HGB |  
| ------- | ----- | ----- |
|accuracy:| 0.834 | 0.905 |
|ROC-AUC: | 0.837 | 0.931 |
|F1-score| 0.652 | 0.803 |

|**69** | Tree | HGB |  
| ------- | ----- | ----- |
|accuracy:| 0.831 | 0.903 |
|ROC-AUC: | 0.843 | 0.934 |
|F1-score| 0.656 | 0.795 |

|**420** | Tree | HGB |  
| ------- | ----- | ----- |
|accuracy:| 0.836 | 0.913 |
|ROC-AUC: | 0.84 | 0.933 |
|F1-score| 0.666 | 0.818 |

|**1337** | Tree | HGB |  
| ------- | ----- | ----- |
|accuracy:| 0.827 | 0.908 |
|ROC-AUC: | 0.823 | 0.926 |
|F1-score| 0.633 | 0.806 |


Можно наблюдать изменение метрик на несколько тысячных в разные стороны. Больше всего изменение `random_state` влияет на F1-score


- Ошибки: confusion matrix для лучшей модели + комментарий:

|Confusion matrix| |
|------|-----|
|TN: 2566| FP: 89|
|FN: 252 |TP: 693|

Лучшая модель довольно хорошо классифицирует объекты. `Precision` = 0.886; `Recall`= 0.733.

- Интерпретация: permutation importance (top-10/15) + выводы:   
По permutation importance наиболее значимым признаком оказался f16: при его перемешивании качество модели падает сильнее всего.    
Это говорит о том, что модель активно использует данный признак для принятия решений.     
С учётом описания датасета (наличие нелинейных взаимодействий), вероятно, f16 участвует в одном или нескольких таких взаимодействиях, что хорошо улавливается ансамблевыми моделями.   
Это соответствует ожиданиям: ансамбли деревьев способны эффективно извлекать нелинейные зависимости и выигрывают у базовых линейных моделей.   

## 6. Conclusion

3-6 коротких тезисов: что вы поняли про деревья/ансамбли и про честный ML-протокол.
